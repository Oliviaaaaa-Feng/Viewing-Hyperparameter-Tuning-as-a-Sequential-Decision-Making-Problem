{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PueQ0U-ojdIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5821b4-4444-48a6-b2fc-6d0dbaa1ed63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_covtype\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
        "import itertools\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data & Parameter\n"
      ],
      "metadata": {
        "id": "nq48drhTrgIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Digits dataset"
      ],
      "metadata": {
        "id": "YmT1VyqnsDG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TdZx22o2B03"
      },
      "outputs": [],
      "source": [
        "digits_data = load_digits()\n",
        "X = digits_data.data\n",
        "y = digits_data.target\n",
        "df = pd.DataFrame(X, columns=digits_data.feature_names)\n",
        "df['target'] = y\n",
        "df.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kaggle dataset"
      ],
      "metadata": {
        "id": "mnyspl2dsIGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.read_csv('application_train.csv')\n",
        "features = features.sample(n=16000, random_state=42)\n",
        "features = features.select_dtypes('number')\n",
        "labels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\n",
        "features = features.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=6000, random_state=50)\n",
        "features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "lH0VApQYsMgI",
        "outputId": "91efbffc-3b0e-41e8-d954-e4b2c7e61bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'application_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-88d87a0e3b07>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'application_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SK_ID_CURR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'application_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search Space"
      ],
      "metadata": {
        "id": "bQL-z2Fpsmae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions_dt = {\n",
        "    'max_depth': list(range(3, 16)),\n",
        "    'min_samples_split': list(range(2, 21)),\n",
        "    'min_samples_leaf': list(range(1, 11)),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "param_distributions_lgb = {\n",
        "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "    'num_leaves': list(range(20, 150)),\n",
        "    'learning_rate': (0.005, 0.5),\n",
        "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
        "    'min_child_samples': list(range(20, 500, 5)),\n",
        "    'reg_alpha': (0, 1),\n",
        "    'reg_lambda': (0, 1),\n",
        "    'colsample_bytree': (0.6, 1),\n",
        "    'subsample': (0.5, 1),\n",
        "    'is_unbalance': [True, False]\n",
        "}\n",
        "\n",
        "param_distributions_svm = {\n",
        "    'C': (0.0001, 1000),\n",
        "    'gamma': (0.000001, 10),\n",
        "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'shrinking': [True, False],\n",
        "    'tol': (0.00001, 0.01),\n",
        "    'probability': [True, False]\n",
        "}\n",
        "\n",
        "param_distributions_obj = {\n",
        "    \"x1\": (0, 10),\n",
        "    \"x2\": (0, 10),\n",
        "    \"x3\": [1,2,3],\n",
        "}"
      ],
      "metadata": {
        "id": "tmjpN0f1slyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-tE0xe8W898"
      },
      "source": [
        "# Random Search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# digits - decision tree\n",
        "n_iter_search = 20\n",
        "dt_results = []\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_default = dt_clf.predict(X_test)\n",
        "y_pred_default_proba = dt_clf.predict_proba(X_test)\n",
        "default_accuracy = accuracy_score(y_test, y_pred_default)\n",
        "default_roc_auc = roc_auc_score(y_test_bin, y_pred_default_proba, average='weighted', multi_class='ovr')\n",
        "\n",
        "best_accuracy = 0\n",
        "best_roc_auc = 0\n",
        "\n",
        "best_params = {}\n",
        "\n",
        "for i in range(n_iter_search):\n",
        "    sampled_params = {\n",
        "        'max_depth': random.choice(param_distributions_dt['max_depth']),\n",
        "        'min_samples_split': random.choice(param_distributions_dt['min_samples_split']),\n",
        "        'min_samples_leaf': random.choice(param_distributions_dt['min_samples_leaf']),\n",
        "        'criterion': random.choice(param_distributions_dt['criterion']),\n",
        "    }\n",
        "\n",
        "    dt_clf = DecisionTreeClassifier(\n",
        "        max_depth=sampled_params['max_depth'],\n",
        "        min_samples_split=sampled_params['min_samples_split'],\n",
        "        min_samples_leaf=sampled_params['min_samples_leaf'],\n",
        "        criterion=sampled_params['criterion'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    y_pred = dt_clf.predict(X_test)\n",
        "    y_pred_proba = dt_clf.predict_proba(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
        "    # print(i, best_accuracy)\n",
        "\n",
        "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
        "        best_accuracy = accuracy\n",
        "        best_roc_auc = roc_auc\n",
        "        best_params = sampled_params\n",
        "\n",
        "    print(i, best_accuracy)\n",
        "\n",
        "# Store results\n",
        "dt_results.append({\n",
        "    'dataset': 'digits',\n",
        "    'best_params': best_params,\n",
        "    'accuracy': best_accuracy,\n",
        "    'roc_auc': best_roc_auc,\n",
        "    'default_accuracy': default_accuracy,\n",
        "    'default_roc_auc': default_roc_auc,\n",
        "    'n_iter': n_iter_search\n",
        "})\n",
        "\n",
        "# Display the results for Decision Tree Randomized Search\n",
        "print(\"\\nDecisionTreeClassifier Manual Randomized Search Results:\")\n",
        "for result in dt_results:\n",
        "    print(f\"Dataset: {result['dataset']}\")\n",
        "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
        "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
        "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
        "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
        "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
        "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLisbq487yq8",
        "outputId": "5cf6ea2a-1ed0-4bd9-9595-8aa16c88f015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.8305555555555556\n",
            "1 0.8305555555555556\n",
            "2 0.8305555555555556\n",
            "3 0.8722222222222222\n",
            "4 0.8722222222222222\n",
            "5 0.8722222222222222\n",
            "6 0.8722222222222222\n",
            "7 0.8722222222222222\n",
            "8 0.8722222222222222\n",
            "9 0.875\n",
            "10 0.875\n",
            "11 0.875\n",
            "12 0.875\n",
            "13 0.875\n",
            "14 0.875\n",
            "15 0.875\n",
            "16 0.875\n",
            "17 0.875\n",
            "18 0.875\n",
            "19 0.875\n",
            "\n",
            "DecisionTreeClassifier Manual Randomized Search Results:\n",
            "Dataset: digits\n",
            "Best Hyperparameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'entropy'}\n",
            "Tuned Accuracy: 0.875\n",
            "Tuned ROC AUC: 0.961669239493184\n",
            "Default Accuracy: 0.8416666666666667\n",
            "Default ROC AUC: 0.9117326702800151\n",
            "Number of Iterations: 20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier Manual Randomized Search Results:\\\n",
        "Dataset: digits\\\n",
        "Best Hyperparameters: {'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
        "Tuned Accuracy: 0.8888888888888888\\\n",
        "Tuned ROC AUC: 0.9434490095095995\\\n",
        "Default Accuracy: 0.8416666666666667\\\n",
        "Default ROC AUC: 0.9117326702800151\\\n",
        "Number of Iterations: 100"
      ],
      "metadata": {
        "id": "BH520AQ7-Gog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggel dataset - decision tree\n",
        "n_iter_search = 100\n",
        "dt_results = []\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(train_features, train_labels)\n",
        "\n",
        "y_pred_default = dt_clf.predict(test_features)\n",
        "y_pred_default_proba = dt_clf.predict_proba(test_features)[:, 1]\n",
        "default_accuracy = accuracy_score(test_labels, y_pred_default)\n",
        "default_roc_auc = roc_auc_score(test_labels, y_pred_default_proba)\n",
        "\n",
        "best_accuracy = 0\n",
        "best_roc_auc = 0\n",
        "best_params = {}\n",
        "\n",
        "for i in range(n_iter_search):\n",
        "    sampled_params = {\n",
        "        'max_depth': random.choice(param_distributions_dt['max_depth']),\n",
        "        'min_samples_split': random.choice(param_distributions_dt['min_samples_split']),\n",
        "        'min_samples_leaf': random.choice(param_distributions_dt['min_samples_leaf']),\n",
        "        'criterion': random.choice(param_distributions_dt['criterion']),\n",
        "    }\n",
        "\n",
        "    dt_clf = DecisionTreeClassifier(\n",
        "        max_depth=sampled_params['max_depth'],\n",
        "        min_samples_split=sampled_params['min_samples_split'],\n",
        "        min_samples_leaf=sampled_params['min_samples_leaf'],\n",
        "        criterion=sampled_params['criterion'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    dt_clf.fit(train_features, train_labels)\n",
        "    y_pred = dt_clf.predict(test_features)\n",
        "    y_pred_proba = dt_clf.predict_proba(test_features)[:, 1]\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "    roc_auc = roc_auc_score(test_labels, y_pred_proba)\n",
        "\n",
        "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
        "        best_accuracy = accuracy\n",
        "        best_roc_auc = roc_auc\n",
        "        best_params = sampled_params\n",
        "\n",
        "# Store results\n",
        "dt_results.append({\n",
        "    'dataset': 'application_train.csv',\n",
        "    'best_params': best_params,\n",
        "    'accuracy': best_accuracy,\n",
        "    'roc_auc': best_roc_auc,\n",
        "    'default_accuracy': default_accuracy,\n",
        "    'default_roc_auc': default_roc_auc,\n",
        "    'n_iter': n_iter_search\n",
        "})\n",
        "\n",
        "# Display the results for Decision Tree Randomized Search\n",
        "print(\"\\nDecisionTreeClassifier Manual Randomized Search Results:\")\n",
        "for result in dt_results:\n",
        "    print(f\"Dataset: {result['dataset']}\")\n",
        "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
        "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
        "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
        "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
        "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
        "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqJSY27P2hjs",
        "outputId": "9f70caea-e95d-4247-d5ac-af4925641541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DecisionTreeClassifier Manual Randomized Search Results:\n",
            "Dataset: application_train.csv\n",
            "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
            "Tuned Accuracy: 0.919\n",
            "Tuned ROC AUC: 0.6923243267044903\n",
            "Default Accuracy: 0.8478333333333333\n",
            "Default ROC AUC: 0.5335162571591058\n",
            "Number of Iterations: 100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier Manual Randomized Search Results:\\\n",
        "Dataset: application_train.csv\\\n",
        "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
        "Tuned Accuracy: 0.919\\\n",
        "Tuned ROC AUC: 0.6923243267044903\\\n",
        "Default Accuracy: 0.8478333333333333\\\n",
        "Default ROC AUC: 0.5335162571591058\\\n",
        "Number of Iterations: 100\n"
      ],
      "metadata": {
        "id": "5VqKp9Zq915b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggle dataset - lgb\n",
        "n_iter_search = 100\n",
        "lgb_results = []\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(random_state=42, force_col_wise=True, verbose=-1)\n",
        "\n",
        "lgb_clf.fit(train_features, train_labels)\n",
        "y_pred_default = lgb_clf.predict(test_features)\n",
        "default_accuracy = accuracy_score(test_labels, y_pred_default)\n",
        "default_roc_auc = roc_auc_score(test_labels, lgb_clf.predict_proba(test_features)[:, 1])\n",
        "\n",
        "best_accuracy = 0\n",
        "best_roc_auc = 0\n",
        "best_params = {}\n",
        "\n",
        "for i in range(n_iter_search):\n",
        "    sampled_params = {\n",
        "        'boosting_type': random.choice(param_distributions_lgb['boosting_type']),\n",
        "        'num_leaves': random.choice(param_distributions_lgb['num_leaves']),\n",
        "        'learning_rate': random.uniform(*param_distributions_lgb['learning_rate']),\n",
        "        'subsample_for_bin': random.choice(param_distributions_lgb['subsample_for_bin']),\n",
        "        'min_child_samples': random.choice(param_distributions_lgb['min_child_samples']),\n",
        "        'reg_alpha': random.uniform(*param_distributions_lgb['reg_alpha']),\n",
        "        'reg_lambda': random.uniform(*param_distributions_lgb['reg_lambda']),\n",
        "        'colsample_bytree': random.uniform(*param_distributions_lgb['colsample_bytree']),\n",
        "        'is_unbalance': random.choice(param_distributions_lgb['is_unbalance'])\n",
        "    }\n",
        "\n",
        "    # if sampled_params['boosting_type'] == 'goss':\n",
        "    #     sampled_params['subsample'] = 1.0\n",
        "    # else:\n",
        "    #     sampled_params['subsample'] = random.choice(param_grid['subsample'])\n",
        "\n",
        "    lgb_clf = lgb.LGBMClassifier(\n",
        "        boosting_type=sampled_params['boosting_type'],\n",
        "        num_leaves=sampled_params['num_leaves'],\n",
        "        learning_rate=sampled_params['learning_rate'],\n",
        "        subsample_for_bin=sampled_params['subsample_for_bin'],\n",
        "        min_child_samples=sampled_params['min_child_samples'],\n",
        "        reg_alpha=sampled_params['reg_alpha'],\n",
        "        reg_lambda=sampled_params['reg_lambda'],\n",
        "        colsample_bytree=sampled_params['colsample_bytree'],\n",
        "        # subsample=sampled_params['subsample'],\n",
        "        is_unbalance=sampled_params['is_unbalance'],\n",
        "        random_state=42,\n",
        "        force_col_wise=True,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    lgb_clf.fit(train_features, train_labels)\n",
        "    y_pred = lgb_clf.predict(test_features)\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "    roc_auc = roc_auc_score(test_labels, lgb_clf.predict_proba(test_features)[:, 1])\n",
        "\n",
        "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
        "        best_accuracy = accuracy\n",
        "        best_roc_auc = roc_auc\n",
        "        best_params = sampled_params\n",
        "\n",
        "lgb_results.append({\n",
        "    'dataset': 'application_train.csv',\n",
        "    'best_params': best_params,\n",
        "    'accuracy': best_accuracy,\n",
        "    'roc_auc': best_roc_auc,\n",
        "    'default_accuracy': default_accuracy,\n",
        "    'default_roc_auc': default_roc_auc,\n",
        "    'n_iter': n_iter_search\n",
        "})\n",
        "\n",
        "# Display the results for LightGBM Randomized Search\n",
        "print(\"\\nLightGBM Manual Randomized Search Results:\")\n",
        "for result in lgb_results:\n",
        "    print(f\"Dataset: {result['dataset']}\")\n",
        "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
        "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
        "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
        "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
        "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
        "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWABjg0t1oO2",
        "outputId": "3091cd01-17fa-42cd-fd29-939fd8e2beba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LightGBM Manual Randomized Search Results:\n",
            "Dataset: application_train.csv\n",
            "Best Hyperparameters: {'boosting_type': 'gbdt', 'num_leaves': 35, 'learning_rate': 0.02210978994109018, 'subsample_for_bin': 40000, 'min_child_samples': 455, 'reg_alpha': 0.8680259780481667, 'reg_lambda': 0.2541190497499861, 'colsample_bytree': 0.7688300660703605, 'is_unbalance': False}\n",
            "Tuned Accuracy: 0.919\n",
            "Tuned ROC AUC: 0.7409795641770816\n",
            "Default Accuracy: 0.916\n",
            "Default ROC AUC: 0.7119893842982546\n",
            "Number of Iterations: 100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM Manual Randomized Search Results:\\\n",
        "Dataset: application_train.csv\\\n",
        "Best Hyperparameters: {'boosting_type': 'gbdt', 'num_leaves': 35, 'learning_rate': 0.02210978994109018, 'subsample_for_bin': 40000, 'min_child_samples': 455, 'reg_alpha': 0.8680259780481667, 'reg_lambda': 0.2541190497499861, 'colsample_bytree': 0.7688300660703605, 'is_unbalance': False}\\\n",
        "Tuned Accuracy: 0.919\\\n",
        "Tuned ROC AUC: 0.7409795641770816\\\n",
        "Default Accuracy: 0.916\\\n",
        "Default ROC AUC: 0.7119893842982546\\\n",
        "Number of Iterations: 100"
      ],
      "metadata": {
        "id": "XjC4WKhpA8FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions_obj = {\n",
        "    \"x1\": (0, 10),\n",
        "    \"x2\": (0, 10),\n",
        "    \"x3\": [1,2,3],\n",
        "}\n",
        "\n",
        "def objective_function(params):\n",
        "    x1, x2, x3 = params['x1'], params['x2'], params['x3']\n",
        "    return -((x1 - 3)**2 + (x2 - 5)**2 - x3 + np.random.normal(0, 0.1))\n",
        "\n",
        "n_iter = 20\n",
        "all_params = []\n",
        "all_results = []\n",
        "\n",
        "best_params = None\n",
        "best_value = float('inf')\n",
        "\n",
        "for i in range(n_iter):\n",
        "    sampled_params = {\n",
        "        'x1': random.uniform(0, 10),\n",
        "        'x2': random.uniform(0, 10),\n",
        "        'x3': random.choice([1, 2, 3])\n",
        "    }\n",
        "\n",
        "    value = objective_function(sampled_params)\n",
        "\n",
        "    all_params.append(sampled_params)\n",
        "    all_results.append(value)\n",
        "\n",
        "    if value < best_value:\n",
        "        best_value = value\n",
        "        best_params = sampled_params\n",
        "\n",
        "for i in range(n_iter):\n",
        "    print(f\"Iteration {i+1}: Params = {all_params[i]}, Objective Value = {all_results[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evHft59Mq75L",
        "outputId": "1bb79d80-db6f-4fc1-8e0d-fd8239d125e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Params = {'x1': 8.014669648298035, 'x2': 1.4997416921347784, 'x3': 2}, Objective Value = -35.39358931490635\n",
            "Iteration 2: Params = {'x1': 8.527242568781134, 'x2': 2.5260501283287775, 'x3': 1}, Objective Value = -35.764081344819395\n",
            "Iteration 3: Params = {'x1': 6.7358984612174595, 'x2': 0.6000051146780694, 'x3': 1}, Objective Value = -32.477607180753424\n",
            "Iteration 4: Params = {'x1': 3.050611366766721, 'x2': 4.368568072912441, 'x3': 1}, Objective Value = 0.6390531898387992\n",
            "Iteration 5: Params = {'x1': 5.607597671725423, 'x2': 1.4520640004443652, 'x3': 3}, Objective Value = -16.387794883484492\n",
            "Iteration 6: Params = {'x1': 8.997413325565557, 'x2': 9.152722120966654, 'x3': 2}, Objective Value = -51.131505659550974\n",
            "Iteration 7: Params = {'x1': 0.06916840400217006, 'x2': 0.5894038049574968, 'x3': 2}, Objective Value = -26.046825652228225\n",
            "Iteration 8: Params = {'x1': 3.4972472248647737, 'x2': 8.994807021731011, 'x3': 3}, Objective Value = -13.14529466789477\n",
            "Iteration 9: Params = {'x1': 2.8366285277814174, 'x2': 6.807100080051201, 'x3': 1}, Objective Value = -2.281123413321539\n",
            "Iteration 10: Params = {'x1': 5.687537582066334, 'x2': 4.402853063454608, 'x3': 3}, Objective Value = -4.42176470566289\n",
            "Iteration 11: Params = {'x1': 6.626340871339424, 'x2': 5.994688973645076, 'x3': 2}, Objective Value = -12.0188857322115\n",
            "Iteration 12: Params = {'x1': 9.148257858033626, 'x2': 3.302576064798386, 'x3': 2}, Objective Value = -38.56349804863269\n",
            "Iteration 13: Params = {'x1': 0.1298148506507768, 'x2': 3.6362588496887716, 'x3': 2}, Objective Value = -8.080210279096864\n",
            "Iteration 14: Params = {'x1': 9.252744533705599, 'x2': 4.914727804748821, 'x3': 3}, Objective Value = -36.23320398748356\n",
            "Iteration 15: Params = {'x1': 2.824646870387939, 'x2': 9.012120063734814, 'x3': 2}, Objective Value = -14.067275097826975\n",
            "Iteration 16: Params = {'x1': 1.367511952109246, 'x2': 5.307143632072478, 'x3': 2}, Objective Value = -0.636904790545922\n",
            "Iteration 17: Params = {'x1': 2.0707425589809136, 'x2': 4.308247224289512, 'x3': 3}, Objective Value = 1.646430800209443\n",
            "Iteration 18: Params = {'x1': 9.534691501148421, 'x2': 8.763750399090815, 'x3': 1}, Objective Value = -55.99119897604776\n",
            "Iteration 19: Params = {'x1': 1.2907788772310813, 'x2': 0.18008137650001643, 'x3': 2}, Objective Value = -24.091492319253824\n",
            "Iteration 20: Params = {'x1': 8.365171186790002, 'x2': 3.6118781242806497, 'x3': 3}, Objective Value = -27.72728824484924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPaZjVKkYH0D"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# digits - decision tree\n",
        "keys, values = zip(*param_distributions_dt.items())\n",
        "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "dt_results = []\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_default = dt_clf.predict(X_test)\n",
        "y_pred_default_proba = dt_clf.predict_proba(X_test)\n",
        "default_accuracy = accuracy_score(y_test, y_pred_default)\n",
        "default_roc_auc = roc_auc_score(y_test_bin, y_pred_default_proba, average='weighted', multi_class='ovr')\n",
        "\n",
        "best_accuracy = 0\n",
        "best_roc_auc = 0\n",
        "best_params = {}\n",
        "\n",
        "for params in param_combinations:\n",
        "    dt_clf = DecisionTreeClassifier(\n",
        "        max_depth=params['max_depth'],\n",
        "        min_samples_split=params['min_samples_split'],\n",
        "        min_samples_leaf=params['min_samples_leaf'],\n",
        "        criterion=params['criterion'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    y_pred = dt_clf.predict(X_test)\n",
        "    y_pred_proba = dt_clf.predict_proba(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
        "\n",
        "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
        "        best_accuracy = accuracy\n",
        "        best_roc_auc = roc_auc\n",
        "        best_params = params\n",
        "\n",
        "dt_results.append({\n",
        "    'dataset': 'digits',\n",
        "    'best_params': best_params,\n",
        "    'accuracy': best_accuracy,\n",
        "    'roc_auc': best_roc_auc,\n",
        "    'default_accuracy': default_accuracy,\n",
        "    'default_roc_auc': default_roc_auc,\n",
        "    'n_iter': len(param_combinations)\n",
        "})\n",
        "\n",
        "print(\"\\nDecisionTreeClassifier Manual Grid Search Results:\")\n",
        "for result in dt_results:\n",
        "    print(f\"Dataset: {result['dataset']}\")\n",
        "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
        "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
        "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
        "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
        "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
        "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "R2XPQk7f79nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier Manual Grid Search Results:\\\n",
        "Dataset: digits\\\n",
        "Best Hyperparameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
        "Tuned Accuracy: 0.8944444444444445\\\n",
        "Tuned ROC AUC: 0.9447431743279776\\\n",
        "Default Accuracy: 0.8416666666666667\\\n",
        "Default ROC AUC: 0.9117326702800151\\\n",
        "Number of Iterations: 4940"
      ],
      "metadata": {
        "id": "raFVZ9PN8OGS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrZ_Dx24xCfj"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DxoKhqexRzx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "class bayesian_optimization():\n",
        "    def __init__(self, objective, space, iterations=30, explore='ei', min_start_size=10):\n",
        "        self.objective = objective\n",
        "        self.space = space\n",
        "        self.feature_name = list(space.keys())\n",
        "        self.iterations = iterations\n",
        "        self.model = GaussianProcessRegressor(kernel=RBF(), alpha=1e-6, normalize_y=True)\n",
        "        self.explore = self.exploration_strategy(explore)\n",
        "        self.min_start_size = min_start_size\n",
        "        self.X = []\n",
        "        self.Y = []\n",
        "        self.preprocess()\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.feature_num = len(self.space)\n",
        "        self.feature_type = {}\n",
        "        for feature, value in self.space.items():\n",
        "            if isinstance(value, list):\n",
        "                self.feature_type[feature] = 'categorical'\n",
        "            else:\n",
        "                assert(isinstance(value, tuple))\n",
        "                self.feature_type[feature] = 'continuous'\n",
        "\n",
        "    def feature_dict_to_array(self, feature_dicts):\n",
        "        # print(feature_dicts)\n",
        "        feature_array = np.zeros((len(feature_dicts), self.feature_num))\n",
        "        for i, feature in enumerate(self.feature_name):\n",
        "            for j, feature_dict in enumerate(feature_dicts):\n",
        "                feature_array[j, i] = feature_dict[feature]\n",
        "        return feature_array\n",
        "\n",
        "    def feature_array_to_dict(self, feature_array):\n",
        "        feature_dict = []\n",
        "        for i in range(feature_array.shape[0]):\n",
        "            feature_dict.append(dict(zip(self.feature_name, feature_array[i])))\n",
        "        return feature_dict\n",
        "\n",
        "\n",
        "    def random_sample(self, sample_size=5):\n",
        "        from tqdm import tqdm\n",
        "        candidates = {}\n",
        "        # for feature, value in tqdm(self.space.items()):\n",
        "        for feature, value in self.space.items():\n",
        "            if self.feature_type[feature] == 'categorical':\n",
        "                candidates[feature] = np.random.choice(value, sample_size)\n",
        "            else:\n",
        "                assert(self.feature_type[feature] == 'continuous')\n",
        "                if value[1] > 1:\n",
        "                    candidates[feature] = np.random.randint(value[0], value[1], sample_size)\n",
        "                else:\n",
        "                    candidates[feature] = np.random.uniform(value[0], value[1], sample_size)\n",
        "        ret = []\n",
        "        for i in range(sample_size):\n",
        "            ret.append({key: candidates[key][i] for key in candidates})\n",
        "        return ret\n",
        "\n",
        "    def exploration_strategy(self, explore='ei'):\n",
        "        if explore == 'ei':\n",
        "            def ei(x, gp, y_min):\n",
        "                x = np.array(x)\n",
        "                mu, sigma = gp.predict(x, return_std=True)\n",
        "                sigma += 1e-9\n",
        "                improvement = y_min - mu\n",
        "                z = np.array(improvement) / np.array(sigma)\n",
        "                return improvement * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "            return ei\n",
        "        elif explore == 'greedy':\n",
        "            def greedy(x, gp, _):\n",
        "                mu, _ = gp.predict(x, return_std=True)\n",
        "                return -mu\n",
        "            return greedy\n",
        "        elif explore == 'ucb':\n",
        "            def ucb(x, gp, _):\n",
        "                mu, sigma = gp.predict(x, return_std=True)\n",
        "                return mu + 1.96 * sigma\n",
        "            return ucb\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported exploration strategy. Use 'ei', 'greedy', or 'ucb'.\")\n",
        "\n",
        "    def get_next_point(self, sample_size=5, return_size=1):\n",
        "        candidates = self.random_sample(sample_size)\n",
        "        candidates = self.feature_dict_to_array(candidates)\n",
        "        acq_values = self.explore(candidates, self.model, min(self.Y))\n",
        "        best_indices = np.argsort(acq_values)[-return_size:]\n",
        "        return candidates[best_indices]\n",
        "\n",
        "    def update_model(self):\n",
        "        self.model.fit(self.feature_dict_to_array(self.X), np.array(self.Y))\n",
        "\n",
        "    def run(self):\n",
        "        from tqdm import tqdm\n",
        "        for i in tqdm(range(self.iterations)):\n",
        "            # print(f\"Iteration {i+1}/{self.iterations}\")\n",
        "            if len(self.X) < self.min_start_size:\n",
        "                x_next = self.random_sample(self.min_start_size)\n",
        "            else:\n",
        "                x_next = self.get_next_point()\n",
        "                x_next = self.feature_array_to_dict(x_next)\n",
        "\n",
        "            y_next = []\n",
        "            for x in x_next:\n",
        "                y_next.append(self.objective(x))\n",
        "            # print(y_next)\n",
        "            self.X.extend(x_next)\n",
        "            self.Y.extend(y_next)\n",
        "            self.update_model()\n",
        "            print(f\"iter{i+1}, Best value so far: {min(self.Y)}\")\n",
        "\n",
        "        best_idx = np.argmin(self.Y)\n",
        "        return {\"best_x\": self.X[best_idx], \"best_y\": self.Y[best_idx]}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_covtype\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import itertools\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_distributions_svm = {\n",
        "    'C': (0.0001, 1000),\n",
        "    'gamma': (0.000001, 10),\n",
        "    'kernel': [0, 1, 2],\n",
        "    'class_weight': [0, 1],\n",
        "    'shrinking': [0, 1],\n",
        "    'tol': (0.00001, 0.01),\n",
        "    'probability': [0, 1]\n",
        "}\n",
        "\n",
        "# from sklearn.datasets import fetch_20newsgroups\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "kernel_array = ['poly', 'rbf', 'sigmoid']\n",
        "class_weight_array = [None, 'balanced']\n",
        "shrinking_array = [True, False]\n",
        "probability_array = [True, False]\n",
        "\n",
        "\n",
        "def objective_svm(params):\n",
        "    params2 = params.copy()\n",
        "    params2['kernel'] = kernel_array[int(params['kernel'])]\n",
        "    params2['C'] = float(params['C'])\n",
        "    params2['class_weight'] = class_weight_array[int(params['class_weight'])]\n",
        "    params2['shrinking'] = shrinking_array[int(params['shrinking'])]\n",
        "    params2['probability'] = probability_array[int(params['probability'])]\n",
        "\n",
        "    model = SVC(**params2)\n",
        "    # model.fit(train_features, train_labels)\n",
        "    # y_pred = model.predict(test_features)\n",
        "    # accuracy = accuracy_score(test_labels, y_pred)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return -accuracy\n",
        "\n",
        "bo_svm = bayesian_optimization(\n",
        "    objective=objective_svm,\n",
        "    space=param_distributions_svm,\n",
        "    iterations=25,\n",
        "    explore='ei',\n",
        "    min_start_size=1,\n",
        ")\n",
        "\n",
        "result_svm = bo_svm.run()\n",
        "print(\"SVM最佳超参数配置:\", result_svm[\"best_x\"])\n",
        "print(\"SVM最佳目标值:\", result_svm[\"best_y\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdPx369kfesC",
        "outputId": "d519c5ce-3ea1-41b7-8c21-b80d88d5c918"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODU633A8xUED",
        "outputId": "ea10c27e-626b-4a78-aac8-712248a49e80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best config: [2.97526837 5.03082013]\n",
            "best result: -9.02749861465481e-05\n"
          ]
        }
      ],
      "source": [
        "param_distributions_lgb = {\n",
        "    # 'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "    'boosting_type': [0, 1, 2],\n",
        "    'num_leaves': (20, 150),\n",
        "    'learning_rate': (0.005, 0.5),\n",
        "    'subsample_for_bin': (20000, 300000),\n",
        "    'min_child_samples': (20, 500),\n",
        "    'reg_alpha': (0, 1),\n",
        "    'reg_lambda': (0, 1),\n",
        "    'colsample_bytree': (0.6, 1),\n",
        "    'subsample': (0.5, 1),\n",
        "    # 'is_unbalance': [True, False]\n",
        "    'is_unbalance': [0, 1]\n",
        "}\n",
        "type_array = ['gbdt', 'goss', 'dart']\n",
        "unbalance_array = [True, False]\n",
        "def objective_lgb(params):\n",
        "    params2 = params.copy()\n",
        "    params2['boosting_type'] = type_array[int(params['boosting_type'])]\n",
        "    params2['is_unbalance'] = unbalance_array[int(params['is_unbalance'])]\n",
        "    params2['num_leaves'] = int(params['num_leaves'])\n",
        "    params2['subsample_for_bin'] = int(params['subsample_for_bin'])\n",
        "    params2['min_child_samples'] = int(params['min_child_samples'])\n",
        "    model = lgb.LGBMClassifier(**params2, random_state=42, force_col_wise=True, verbose=-1)\n",
        "    model.fit(train_features, train_labels)\n",
        "    y_pred = model.predict(test_features)\n",
        "    return -accuracy_score(test_labels, y_pred)\n",
        "\n",
        "bo = bayesian_optimization(\n",
        "    objective=objective_lgb,\n",
        "    space=param_distributions_lgb,\n",
        "    iterations=25,\n",
        "    explore='ei',\n",
        "    min_start_size=5,\n",
        ")\n",
        "\n",
        "result = bo.run()\n",
        "\n",
        "# 打印结果\n",
        "print(\"最佳超参数配置:\", result[\"best_x\"])\n",
        "print(\"最佳目标值:\", result[\"best_y\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# digits - decision tree"
      ],
      "metadata": {
        "id": "HPrrE5lR0rqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggle dataset - decision tree"
      ],
      "metadata": {
        "id": "1usLZN7G0r7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggle dataset - gbm"
      ],
      "metadata": {
        "id": "Q4NUvO090sPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqMW8TmsJMmP"
      },
      "source": [
        "# Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class q_learning():\n",
        "    def __init__(self, alpha, gamma, epsilon, proportional_factor, max_iterations,\n",
        "                 space, model, X_train, y_train, X_test, y_test):\n",
        "        self.q_table = {}\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.proportional_factor = proportional_factor\n",
        "        self.max_iterations = max_iterations\n",
        "        self.space = space\n",
        "        self.model = model\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.actions = {key: [\"increase\", \"stay\", \"decrease\"] for key in self.space.keys()}\n",
        "\n",
        "    def state_selection(self):\n",
        "        state = {}\n",
        "        for key, values in self.space.items():\n",
        "            if type(values) == list:\n",
        "                state[key] = random.choice(values)\n",
        "            else:\n",
        "                state[key] = random.uniform(values[0], values[1])\n",
        "        return state\n",
        "\n",
        "    def exploration_strategy(self, state):\n",
        "        action_set = {}\n",
        "        for key in self.space.keys():\n",
        "            if random.uniform(0, 1) < self.epsilon:\n",
        "                action_set[key] = random.choice(self.actions[key])\n",
        "            else:\n",
        "                q_values = self.q_table.get(tuple(state.items()), {}).get(key, {})\n",
        "                action_set[key] = max(q_values, key=q_values.get, default=\"stay\")\n",
        "            self.epsilon *= 0.999\n",
        "        return action_set\n",
        "\n",
        "    def apply_action(self, state, action_set):\n",
        "        new_state = state.copy()\n",
        "\n",
        "        for key, action in action_set.items():\n",
        "            if type(self.space[key]) == list:\n",
        "                value_list = self.space[key]\n",
        "                current_index = value_list.index(new_state[key])\n",
        "\n",
        "                if action == \"increase\":\n",
        "                    new_index = min(current_index + 1, len(value_list) - 1)\n",
        "                elif action == \"decrease\":\n",
        "                    new_index = max(current_index - 1, 0)\n",
        "                else:\n",
        "                    new_index = current_index\n",
        "\n",
        "                new_state[key] = value_list[new_index]\n",
        "\n",
        "            else:\n",
        "                min_val, max_val = self.space[key]\n",
        "                current_value = new_state[key]\n",
        "                self.proportional_factor *= 0.99\n",
        "\n",
        "                if action == \"increase\":\n",
        "                    new_state[key] = min((1 + self.proportional_factor) * current_value, max_val)\n",
        "                elif action == \"decrease\":\n",
        "                    new_state[key] = max((1 - self.proportional_factor) * current_value, min_val)\n",
        "                else:\n",
        "                    new_state[key] = current_value\n",
        "        return new_state\n",
        "\n",
        "    def get_reward(self, state):\n",
        "        params = {k: v for k, v in state.items()}\n",
        "\n",
        "        if self.model == \"dt\":\n",
        "            model = DecisionTreeClassifier(**params, random_state=42)\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "            y_pred = model.predict(self.X_test)\n",
        "            return accuracy_score(self.y_test, y_pred)\n",
        "        else:\n",
        "            return -((state['x1'] - 3)**2 + (state['x2'] - 5)**2  - (state['x3']) + np.random.normal(0, 0.1))\n",
        "\n",
        "    def update_q_table(self, state, action_set, reward, new_state):\n",
        "        state_key = tuple(state.items())\n",
        "        new_state_key = tuple(new_state.items())\n",
        "\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = {}\n",
        "        for key, action in action_set.items():\n",
        "            if key not in self.q_table[state_key]:\n",
        "                self.q_table[state_key][key] = {}\n",
        "            old_q_value = self.q_table[state_key][key].get(action, 0)\n",
        "            future_q_value = max(\n",
        "                self.q_table.get(new_state_key, {}).get(key, {}).values(), default=0\n",
        "            )\n",
        "            new_q_value = old_q_value + self.alpha * (reward + self.gamma * future_q_value - old_q_value)\n",
        "            self.q_table[state_key][key][action] = new_q_value\n",
        "\n",
        "    def run(self):\n",
        "        for iteration in range(self.max_iterations):\n",
        "            state = {key: random.choice(values) for key, values in self.space.items()}\n",
        "\n",
        "            for _ in range(100):\n",
        "                action_set = self.exploration_strategy(state)\n",
        "                new_state = self.apply_action(state, action_set)\n",
        "                reward = self.get_reward(new_state)\n",
        "                self.update_q_table(state, action_set, reward, new_state)\n",
        "                state = new_state\n",
        "        print(len(self.q_table))\n",
        "\n",
        "    def get_best_hyperparameters(self):\n",
        "        self.run()\n",
        "        best_state = max(\n",
        "            (s for s in self.q_table if self.q_table[s]),\n",
        "            key=lambda s: sum(max(self.q_table[s][k].values(), default=0) for k in self.q_table[s]),\n",
        "            default=None\n",
        "        )\n",
        "        return dict(best_state)"
      ],
      "metadata": {
        "id": "ssukyTC29N27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ql = q_learning(\n",
        "    alpha = 0.1,\n",
        "    gamma = 0.9,\n",
        "    epsilon = 0.9,\n",
        "    proportional_factor = 0.1,\n",
        "    max_iterations = 20,\n",
        "    space = param_distributions_dt,\n",
        "    model = \"dt\",\n",
        "    X_train = X_train,\n",
        "    y_train = y_train,\n",
        "    X_test = X_test,\n",
        "    y_test = y_test\n",
        ")\n",
        "result = ql.get_best_hyperparameters()\n",
        "\n",
        "model_final = DecisionTreeClassifier(**result, random_state=42)\n",
        "model_final.fit(X_train, y_train)\n",
        "y_pred = model_final.predict(X_test)\n",
        "y_pred_proba = model_final.predict_proba(X_test)\n",
        "\n",
        "print(result)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "gTLB6m46PNLq",
        "outputId": "def0a8da-47ff-404b-968d-0c7e9624ba18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-fea27cd5753d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-7f683597d33a>\u001b[0m in \u001b[0;36mget_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# best_state = max(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#     (s for s in self.q_table if self.q_table[s]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-7f683597d33a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0maction_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_q_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-7f683597d33a>\u001b[0m in \u001b[0;36mget_reward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \"\"\"\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# digits - decision tree\n",
        "params = []\n",
        "# auc = []\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ql = q_learning(\n",
        "        alpha = 0.1,\n",
        "        gamma = 0.9,\n",
        "        epsilon = 0.9,\n",
        "        proportional_factor = 0.1,\n",
        "        max_iterations = 20,\n",
        "        space = param_distributions_dt,\n",
        "        model = \"dt\",\n",
        "        X_train = X_train,\n",
        "        y_train = y_train,\n",
        "        X_test = X_test,\n",
        "        y_test = y_test\n",
        "    )\n",
        "    result = ql.get_best_hyperparameters()\n",
        "\n",
        "    model_final = DecisionTreeClassifier(**result, random_state=42)\n",
        "    model_final.fit(X_train, y_train)\n",
        "    y_pred = model_final.predict(X_test)\n",
        "    # y_pred_proba = model_final.predict_proba(X_test)\n",
        "\n",
        "    params.append(result)\n",
        "    # auc.append(roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr'))\n",
        "    results.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(params)\n",
        "# print(auc)\n",
        "print(results)\n",
        "print(max(results))"
      ],
      "metadata": {
        "id": "LeZEPQzb9OWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "c83cdc9d-56e4-49cf-955f-0e533ca68645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-51af3fed2d3e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-145-7f683597d33a>\u001b[0m in \u001b[0;36mget_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# best_state = max(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#     (s for s in self.q_table if self.q_table[s]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-145-7f683597d33a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0maction_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_q_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-145-7f683597d33a>\u001b[0m in \u001b[0;36mget_reward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \"\"\"\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obj function\n",
        "params = []\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ql = q_learning(\n",
        "        alpha = 0.1,\n",
        "        gamma = 0.9,\n",
        "        epsilon = 0.9,\n",
        "        proportional_factor = 0.1,\n",
        "        max_iterations = 20,\n",
        "        space = param_distributions_obj,\n",
        "        model = \"obj\",\n",
        "        X_train = X_train,\n",
        "        y_train = y_train,\n",
        "        X_test = X_test,\n",
        "        y_test = y_test\n",
        "    )\n",
        "    result = ql.get_best_hyperparameters()\n",
        "    loss = -((result['x1'] - 3)**2 + (result['x2'] - 5)**2  - (result['x3']) + np.random.normal(0, 0.1))\n",
        "\n",
        "    params.append(result)\n",
        "    results.append(loss)\n",
        "\n",
        "print(params)\n",
        "print(results)\n",
        "print(max(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0d6zObS1qUw",
        "outputId": "b5b1946b-31d4-4d02-f3ed-38a65317b6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251\n",
            "307\n",
            "293\n",
            "193\n",
            "173\n",
            "310\n",
            "242\n",
            "297\n",
            "186\n",
            "208\n",
            "[{'x1': 0.0, 'x2': 9.660738000321029, 'x3': 2}, {'x1': 0.0, 'x2': 6.2129964532848785, 'x3': 3}, {'x1': 4.529635585505561, 'x2': 6.76942991422106, 'x3': 3}, {'x1': 0.0, 'x2': 9.999999999682311, 'x3': 2}, {'x1': 0.0, 'x2': 8.31837142031841, 'x3': 2}, {'x1': 0.0, 'x2': 9.844845852239574, 'x3': 2}, {'x1': 0.0, 'x2': 7.0780149854224605, 'x3': 3}, {'x1': 7.998077289440447, 'x2': 5.03982081954357, 'x3': 2}, {'x1': 0.0, 'x2': 9.999999998209683, 'x3': 2}, {'x1': 0.0, 'x2': 9.343649606355054, 'x3': 3}]\n",
            "[-28.655266166704706, -7.360572355462452, -2.496523487789181, -32.05893780729479, -18.104293723430466, -30.451764081070646, -10.274507617817937, -22.90105920367276, -31.94459964484592, -24.75964627251292]\n",
            "-2.496523487789181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_result = [0.8722222222222222, 0.8694444444444445, 0.8694444444444445, 0.8722222222222222, 0.875, 0.8888888888888888, 0.8888888888888888, 0.875, 0.8361111111111111, 0.8777777777777778]\n",
        "\n",
        "mean = np.mean(dt_result)\n",
        "minimum = np.min(dt_result)\n",
        "maximum = np.max(dt_result)\n",
        "std_dev = np.std(dt_result)\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Minimum:\", minimum)\n",
        "print(\"Maximum:\", maximum)\n",
        "print(\"Standard Deviation:\", std_dev)"
      ],
      "metadata": {
        "id": "7yCVLaUv17dA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb061ed1-098d-4647-e936-72517891f897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.8724999999999999\n",
            "Minimum: 0.8361111111111111\n",
            "Maximum: 0.8888888888888888\n",
            "Standard Deviation: 0.013858299648073781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj_result = [-28.655266166704706, -7.360572355462452, -2.496523487789181, -32.05893780729479, -18.104293723430466, -30.451764081070646, -10.274507617817937, -22.90105920367276, -31.94459964484592, -24.75964627251292]\n",
        "mean = np.mean(obj_result)\n",
        "minimum = np.min(obj_result)\n",
        "maximum = np.max(obj_result)\n",
        "std_dev = np.std(obj_result)\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Minimum:\", minimum)\n",
        "print(\"Maximum:\", maximum)\n",
        "print(\"Standard Deviation:\", std_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CzP7jyVJwPY",
        "outputId": "c9afd756-e7cd-4b0a-8080-27017b7d9c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: -20.90071703606018\n",
            "Minimum: -32.05893780729479\n",
            "Maximum: -2.496523487789181\n",
            "Standard Deviation: 10.29323873933181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'max_depth': 3,\n",
        "    'min_samples_split': 2,\n",
        "    'min_samples_leaf': 1,\n",
        "    'criterion': 'gini'\n",
        "}\n",
        "\n",
        "model = DecisionTreeClassifier(**params, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "a11myRemJ6WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28d141a-d8a9-4854-e252-86715ce3791a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nFP9hElCs8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}