{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PueQ0U-ojdIf",
    "outputId": "bd5821b4-4444-48a6-b2fc-6d0dbaa1ed63"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_covtype\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
    "import itertools\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq48drhTrgIs"
   },
   "source": [
    "# Data & Parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmT1VyqnsDG5"
   },
   "source": [
    "### Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_TdZx22o2B03"
   },
   "outputs": [],
   "source": [
    "digits_data = load_digits()\n",
    "X = digits_data.data\n",
    "y = digits_data.target\n",
    "df = pd.DataFrame(X, columns=digits_data.feature_names)\n",
    "df['target'] = y\n",
    "df.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnyspl2dsIGd"
   },
   "source": [
    "### Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "lH0VApQYsMgI",
    "outputId": "91efbffc-3b0e-41e8-d954-e4b2c7e61bd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245895</th>\n",
       "      <td>2</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>465457.5</td>\n",
       "      <td>52641.0</td>\n",
       "      <td>418500.0</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>-13297</td>\n",
       "      <td>-762</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>-4307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98194</th>\n",
       "      <td>0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>1281712.5</td>\n",
       "      <td>48946.5</td>\n",
       "      <td>1179000.0</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>-14778</td>\n",
       "      <td>-1141</td>\n",
       "      <td>-1610.0</td>\n",
       "      <td>-4546</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36463</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>39109.5</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-17907</td>\n",
       "      <td>-639</td>\n",
       "      <td>-2507.0</td>\n",
       "      <td>-1461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249923</th>\n",
       "      <td>0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>24939.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>-19626</td>\n",
       "      <td>-6982</td>\n",
       "      <td>-11167.0</td>\n",
       "      <td>-3158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158389</th>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>308133.0</td>\n",
       "      <td>15862.5</td>\n",
       "      <td>234000.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-20327</td>\n",
       "      <td>-1105</td>\n",
       "      <td>-7299.0</td>\n",
       "      <td>-494</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "245895             2          207000.0    465457.5      52641.0   \n",
       "98194              0          247500.0   1281712.5      48946.5   \n",
       "36463              0          202500.0    495000.0      39109.5   \n",
       "249923             0          247500.0    254700.0      24939.0   \n",
       "158389             0          112500.0    308133.0      15862.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "245895         418500.0                    0.009630      -13297   \n",
       "98194         1179000.0                    0.006852      -14778   \n",
       "36463          495000.0                    0.035792      -17907   \n",
       "249923         225000.0                    0.046220      -19626   \n",
       "158389         234000.0                    0.018850      -20327   \n",
       "\n",
       "        DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "245895           -762             -637.0            -4307  ...   \n",
       "98194           -1141            -1610.0            -4546  ...   \n",
       "36463            -639            -2507.0            -1461  ...   \n",
       "249923          -6982           -11167.0            -3158  ...   \n",
       "158389          -1105            -7299.0             -494  ...   \n",
       "\n",
       "        FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  \\\n",
       "245895                 0                 0                 0   \n",
       "98194                  0                 0                 0   \n",
       "36463                  0                 0                 0   \n",
       "249923                 0                 0                 0   \n",
       "158389                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "245895                 0                         0.0   \n",
       "98194                  0                         0.0   \n",
       "36463                  0                         0.0   \n",
       "249923                 0                         0.0   \n",
       "158389                 0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "245895                        0.0                         0.0   \n",
       "98194                         0.0                         0.0   \n",
       "36463                         0.0                         0.0   \n",
       "249923                        0.0                         0.0   \n",
       "158389                        0.0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "245895                        1.0                        0.0   \n",
       "98194                         1.0                        0.0   \n",
       "36463                         1.0                        0.0   \n",
       "249923                        0.0                        0.0   \n",
       "158389                        0.0                        0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "245895                         1.0  \n",
       "98194                          3.0  \n",
       "36463                          3.0  \n",
       "249923                         0.0  \n",
       "158389                         4.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('application_train.csv')\n",
    "features = features.sample(n=16000, random_state=42)\n",
    "features = features.select_dtypes('number')\n",
    "labels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "features = features.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=6000, random_state=50)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQL-z2Fpsmae"
   },
   "source": [
    "### Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmjpN0f1slyZ"
   },
   "outputs": [],
   "source": [
    "param_distributions_dt = {\n",
    "    'max_depth': list(range(3, 16)),\n",
    "    'min_samples_split': list(range(2, 21)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "param_distributions_lgb = {\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(20, 150)),\n",
    "    'learning_rate': (0.005, 0.5),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': (0, 1),\n",
    "    'reg_lambda': (0, 1),\n",
    "    'colsample_bytree': (0.6, 1),\n",
    "    'subsample': (0.5, 1),\n",
    "    'is_unbalance': [True, False]\n",
    "}\n",
    "\n",
    "param_distributions_svm = {\n",
    "    'C': (0.0001, 1000),\n",
    "    'gamma': (0.000001, 10),\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'shrinking': [True, False],\n",
    "    'tol': (0.00001, 0.01),\n",
    "    'probability': [True, False]\n",
    "}\n",
    "\n",
    "param_distributions_obj = {\n",
    "    \"x1\": (0, 10),\n",
    "    \"x2\": (0, 10),\n",
    "    \"x3\": [1,2,3],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-tE0xe8W898"
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLisbq487yq8",
    "outputId": "5cf6ea2a-1ed0-4bd9-9595-8aa16c88f015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8305555555555556\n",
      "1 0.8305555555555556\n",
      "2 0.8305555555555556\n",
      "3 0.8722222222222222\n",
      "4 0.8722222222222222\n",
      "5 0.8722222222222222\n",
      "6 0.8722222222222222\n",
      "7 0.8722222222222222\n",
      "8 0.8722222222222222\n",
      "9 0.875\n",
      "10 0.875\n",
      "11 0.875\n",
      "12 0.875\n",
      "13 0.875\n",
      "14 0.875\n",
      "15 0.875\n",
      "16 0.875\n",
      "17 0.875\n",
      "18 0.875\n",
      "19 0.875\n",
      "\n",
      "DecisionTreeClassifier Manual Randomized Search Results:\n",
      "Dataset: digits\n",
      "Best Hyperparameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'entropy'}\n",
      "Tuned Accuracy: 0.875\n",
      "Tuned ROC AUC: 0.961669239493184\n",
      "Default Accuracy: 0.8416666666666667\n",
      "Default ROC AUC: 0.9117326702800151\n",
      "Number of Iterations: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# digits - decision tree\n",
    "n_iter_search = 20\n",
    "dt_results = []\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_default = dt_clf.predict(X_test)\n",
    "y_pred_default_proba = dt_clf.predict_proba(X_test)\n",
    "default_accuracy = accuracy_score(y_test, y_pred_default)\n",
    "default_roc_auc = roc_auc_score(y_test_bin, y_pred_default_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "best_accuracy = 0\n",
    "best_roc_auc = 0\n",
    "\n",
    "best_params = {}\n",
    "\n",
    "for i in range(n_iter_search):\n",
    "    sampled_params = {\n",
    "        'max_depth': random.choice(param_distributions_dt['max_depth']),\n",
    "        'min_samples_split': random.choice(param_distributions_dt['min_samples_split']),\n",
    "        'min_samples_leaf': random.choice(param_distributions_dt['min_samples_leaf']),\n",
    "        'criterion': random.choice(param_distributions_dt['criterion']),\n",
    "    }\n",
    "\n",
    "    dt_clf = DecisionTreeClassifier(\n",
    "        max_depth=sampled_params['max_depth'],\n",
    "        min_samples_split=sampled_params['min_samples_split'],\n",
    "        min_samples_leaf=sampled_params['min_samples_leaf'],\n",
    "        criterion=sampled_params['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "    y_pred_proba = dt_clf.predict_proba(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
    "    # print(i, best_accuracy)\n",
    "\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
    "        best_accuracy = accuracy\n",
    "        best_roc_auc = roc_auc\n",
    "        best_params = sampled_params\n",
    "\n",
    "    print(i, best_accuracy)\n",
    "\n",
    "# Store results\n",
    "dt_results.append({\n",
    "    'dataset': 'digits',\n",
    "    'best_params': best_params,\n",
    "    'accuracy': best_accuracy,\n",
    "    'roc_auc': best_roc_auc,\n",
    "    'default_accuracy': default_accuracy,\n",
    "    'default_roc_auc': default_roc_auc,\n",
    "    'n_iter': n_iter_search\n",
    "})\n",
    "\n",
    "# Display the results for Decision Tree Randomized Search\n",
    "print(\"\\nDecisionTreeClassifier Manual Randomized Search Results:\")\n",
    "for result in dt_results:\n",
    "    print(f\"Dataset: {result['dataset']}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
    "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
    "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
    "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
    "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
    "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH520AQ7-Gog"
   },
   "source": [
    "DecisionTreeClassifier Manual Randomized Search Results:\\\n",
    "Dataset: digits\\\n",
    "Best Hyperparameters: {'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
    "Tuned Accuracy: 0.8888888888888888\\\n",
    "Tuned ROC AUC: 0.9434490095095995\\\n",
    "Default Accuracy: 0.8416666666666667\\\n",
    "Default ROC AUC: 0.9117326702800151\\\n",
    "Number of Iterations: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqJSY27P2hjs",
    "outputId": "9f70caea-e95d-4247-d5ac-af4925641541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier Manual Randomized Search Results:\n",
      "Dataset: application_train.csv\n",
      "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\n",
      "Tuned Accuracy: 0.919\n",
      "Tuned ROC AUC: 0.6923243267044903\n",
      "Default Accuracy: 0.8478333333333333\n",
      "Default ROC AUC: 0.5335162571591058\n",
      "Number of Iterations: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kaggel dataset - decision tree\n",
    "n_iter_search = 100\n",
    "dt_results = []\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(train_features, train_labels)\n",
    "\n",
    "y_pred_default = dt_clf.predict(test_features)\n",
    "y_pred_default_proba = dt_clf.predict_proba(test_features)[:, 1]\n",
    "default_accuracy = accuracy_score(test_labels, y_pred_default)\n",
    "default_roc_auc = roc_auc_score(test_labels, y_pred_default_proba)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_roc_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "for i in range(n_iter_search):\n",
    "    sampled_params = {\n",
    "        'max_depth': random.choice(param_distributions_dt['max_depth']),\n",
    "        'min_samples_split': random.choice(param_distributions_dt['min_samples_split']),\n",
    "        'min_samples_leaf': random.choice(param_distributions_dt['min_samples_leaf']),\n",
    "        'criterion': random.choice(param_distributions_dt['criterion']),\n",
    "    }\n",
    "\n",
    "    dt_clf = DecisionTreeClassifier(\n",
    "        max_depth=sampled_params['max_depth'],\n",
    "        min_samples_split=sampled_params['min_samples_split'],\n",
    "        min_samples_leaf=sampled_params['min_samples_leaf'],\n",
    "        criterion=sampled_params['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_clf.fit(train_features, train_labels)\n",
    "    y_pred = dt_clf.predict(test_features)\n",
    "    y_pred_proba = dt_clf.predict_proba(test_features)[:, 1]\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    roc_auc = roc_auc_score(test_labels, y_pred_proba)\n",
    "\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
    "        best_accuracy = accuracy\n",
    "        best_roc_auc = roc_auc\n",
    "        best_params = sampled_params\n",
    "\n",
    "# Store results\n",
    "dt_results.append({\n",
    "    'dataset': 'application_train.csv',\n",
    "    'best_params': best_params,\n",
    "    'accuracy': best_accuracy,\n",
    "    'roc_auc': best_roc_auc,\n",
    "    'default_accuracy': default_accuracy,\n",
    "    'default_roc_auc': default_roc_auc,\n",
    "    'n_iter': n_iter_search\n",
    "})\n",
    "\n",
    "# Display the results for Decision Tree Randomized Search\n",
    "print(\"\\nDecisionTreeClassifier Manual Randomized Search Results:\")\n",
    "for result in dt_results:\n",
    "    print(f\"Dataset: {result['dataset']}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
    "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
    "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
    "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
    "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
    "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VqKp9Zq915b"
   },
   "source": [
    "DecisionTreeClassifier Manual Randomized Search Results:\\\n",
    "Dataset: application_train.csv\\\n",
    "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
    "Tuned Accuracy: 0.919\\\n",
    "Tuned ROC AUC: 0.6923243267044903\\\n",
    "Default Accuracy: 0.8478333333333333\\\n",
    "Default ROC AUC: 0.5335162571591058\\\n",
    "Number of Iterations: 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWABjg0t1oO2",
    "outputId": "3091cd01-17fa-42cd-fd29-939fd8e2beba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Manual Randomized Search Results:\n",
      "Dataset: application_train.csv\n",
      "Best Hyperparameters: {'boosting_type': 'gbdt', 'num_leaves': 35, 'learning_rate': 0.02210978994109018, 'subsample_for_bin': 40000, 'min_child_samples': 455, 'reg_alpha': 0.8680259780481667, 'reg_lambda': 0.2541190497499861, 'colsample_bytree': 0.7688300660703605, 'is_unbalance': False}\n",
      "Tuned Accuracy: 0.919\n",
      "Tuned ROC AUC: 0.7409795641770816\n",
      "Default Accuracy: 0.916\n",
      "Default ROC AUC: 0.7119893842982546\n",
      "Number of Iterations: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kaggle dataset - lgb\n",
    "n_iter_search = 100\n",
    "lgb_results = []\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=42, force_col_wise=True, verbose=-1)\n",
    "\n",
    "lgb_clf.fit(train_features, train_labels)\n",
    "y_pred_default = lgb_clf.predict(test_features)\n",
    "default_accuracy = accuracy_score(test_labels, y_pred_default)\n",
    "default_roc_auc = roc_auc_score(test_labels, lgb_clf.predict_proba(test_features)[:, 1])\n",
    "\n",
    "best_accuracy = 0\n",
    "best_roc_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "for i in range(n_iter_search):\n",
    "    sampled_params = {\n",
    "        'boosting_type': random.choice(param_distributions_lgb['boosting_type']),\n",
    "        'num_leaves': random.choice(param_distributions_lgb['num_leaves']),\n",
    "        'learning_rate': random.uniform(*param_distributions_lgb['learning_rate']),\n",
    "        'subsample_for_bin': random.choice(param_distributions_lgb['subsample_for_bin']),\n",
    "        'min_child_samples': random.choice(param_distributions_lgb['min_child_samples']),\n",
    "        'reg_alpha': random.uniform(*param_distributions_lgb['reg_alpha']),\n",
    "        'reg_lambda': random.uniform(*param_distributions_lgb['reg_lambda']),\n",
    "        'colsample_bytree': random.uniform(*param_distributions_lgb['colsample_bytree']),\n",
    "        'is_unbalance': random.choice(param_distributions_lgb['is_unbalance'])\n",
    "    }\n",
    "\n",
    "    # if sampled_params['boosting_type'] == 'goss':\n",
    "    #     sampled_params['subsample'] = 1.0\n",
    "    # else:\n",
    "    #     sampled_params['subsample'] = random.choice(param_grid['subsample'])\n",
    "\n",
    "    lgb_clf = lgb.LGBMClassifier(\n",
    "        boosting_type=sampled_params['boosting_type'],\n",
    "        num_leaves=sampled_params['num_leaves'],\n",
    "        learning_rate=sampled_params['learning_rate'],\n",
    "        subsample_for_bin=sampled_params['subsample_for_bin'],\n",
    "        min_child_samples=sampled_params['min_child_samples'],\n",
    "        reg_alpha=sampled_params['reg_alpha'],\n",
    "        reg_lambda=sampled_params['reg_lambda'],\n",
    "        colsample_bytree=sampled_params['colsample_bytree'],\n",
    "        # subsample=sampled_params['subsample'],\n",
    "        is_unbalance=sampled_params['is_unbalance'],\n",
    "        random_state=42,\n",
    "        force_col_wise=True,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    lgb_clf.fit(train_features, train_labels)\n",
    "    y_pred = lgb_clf.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    roc_auc = roc_auc_score(test_labels, lgb_clf.predict_proba(test_features)[:, 1])\n",
    "\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
    "        best_accuracy = accuracy\n",
    "        best_roc_auc = roc_auc\n",
    "        best_params = sampled_params\n",
    "\n",
    "lgb_results.append({\n",
    "    'dataset': 'application_train.csv',\n",
    "    'best_params': best_params,\n",
    "    'accuracy': best_accuracy,\n",
    "    'roc_auc': best_roc_auc,\n",
    "    'default_accuracy': default_accuracy,\n",
    "    'default_roc_auc': default_roc_auc,\n",
    "    'n_iter': n_iter_search\n",
    "})\n",
    "\n",
    "# Display the results for LightGBM Randomized Search\n",
    "print(\"\\nLightGBM Manual Randomized Search Results:\")\n",
    "for result in lgb_results:\n",
    "    print(f\"Dataset: {result['dataset']}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
    "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
    "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
    "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
    "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
    "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjC4WKhpA8FD"
   },
   "source": [
    "LightGBM Manual Randomized Search Results:\\\n",
    "Dataset: application_train.csv\\\n",
    "Best Hyperparameters: {'boosting_type': 'gbdt', 'num_leaves': 35, 'learning_rate': 0.02210978994109018, 'subsample_for_bin': 40000, 'min_child_samples': 455, 'reg_alpha': 0.8680259780481667, 'reg_lambda': 0.2541190497499861, 'colsample_bytree': 0.7688300660703605, 'is_unbalance': False}\\\n",
    "Tuned Accuracy: 0.919\\\n",
    "Tuned ROC AUC: 0.7409795641770816\\\n",
    "Default Accuracy: 0.916\\\n",
    "Default ROC AUC: 0.7119893842982546\\\n",
    "Number of Iterations: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evHft59Mq75L",
    "outputId": "1bb79d80-db6f-4fc1-8e0d-fd8239d125e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Params = {'x1': 8.014669648298035, 'x2': 1.4997416921347784, 'x3': 2}, Objective Value = -35.39358931490635\n",
      "Iteration 2: Params = {'x1': 8.527242568781134, 'x2': 2.5260501283287775, 'x3': 1}, Objective Value = -35.764081344819395\n",
      "Iteration 3: Params = {'x1': 6.7358984612174595, 'x2': 0.6000051146780694, 'x3': 1}, Objective Value = -32.477607180753424\n",
      "Iteration 4: Params = {'x1': 3.050611366766721, 'x2': 4.368568072912441, 'x3': 1}, Objective Value = 0.6390531898387992\n",
      "Iteration 5: Params = {'x1': 5.607597671725423, 'x2': 1.4520640004443652, 'x3': 3}, Objective Value = -16.387794883484492\n",
      "Iteration 6: Params = {'x1': 8.997413325565557, 'x2': 9.152722120966654, 'x3': 2}, Objective Value = -51.131505659550974\n",
      "Iteration 7: Params = {'x1': 0.06916840400217006, 'x2': 0.5894038049574968, 'x3': 2}, Objective Value = -26.046825652228225\n",
      "Iteration 8: Params = {'x1': 3.4972472248647737, 'x2': 8.994807021731011, 'x3': 3}, Objective Value = -13.14529466789477\n",
      "Iteration 9: Params = {'x1': 2.8366285277814174, 'x2': 6.807100080051201, 'x3': 1}, Objective Value = -2.281123413321539\n",
      "Iteration 10: Params = {'x1': 5.687537582066334, 'x2': 4.402853063454608, 'x3': 3}, Objective Value = -4.42176470566289\n",
      "Iteration 11: Params = {'x1': 6.626340871339424, 'x2': 5.994688973645076, 'x3': 2}, Objective Value = -12.0188857322115\n",
      "Iteration 12: Params = {'x1': 9.148257858033626, 'x2': 3.302576064798386, 'x3': 2}, Objective Value = -38.56349804863269\n",
      "Iteration 13: Params = {'x1': 0.1298148506507768, 'x2': 3.6362588496887716, 'x3': 2}, Objective Value = -8.080210279096864\n",
      "Iteration 14: Params = {'x1': 9.252744533705599, 'x2': 4.914727804748821, 'x3': 3}, Objective Value = -36.23320398748356\n",
      "Iteration 15: Params = {'x1': 2.824646870387939, 'x2': 9.012120063734814, 'x3': 2}, Objective Value = -14.067275097826975\n",
      "Iteration 16: Params = {'x1': 1.367511952109246, 'x2': 5.307143632072478, 'x3': 2}, Objective Value = -0.636904790545922\n",
      "Iteration 17: Params = {'x1': 2.0707425589809136, 'x2': 4.308247224289512, 'x3': 3}, Objective Value = 1.646430800209443\n",
      "Iteration 18: Params = {'x1': 9.534691501148421, 'x2': 8.763750399090815, 'x3': 1}, Objective Value = -55.99119897604776\n",
      "Iteration 19: Params = {'x1': 1.2907788772310813, 'x2': 0.18008137650001643, 'x3': 2}, Objective Value = -24.091492319253824\n",
      "Iteration 20: Params = {'x1': 8.365171186790002, 'x2': 3.6118781242806497, 'x3': 3}, Objective Value = -27.72728824484924\n"
     ]
    }
   ],
   "source": [
    "param_distributions_obj = {\n",
    "    \"x1\": (0, 10),\n",
    "    \"x2\": (0, 10),\n",
    "    \"x3\": [1,2,3],\n",
    "}\n",
    "\n",
    "def objective_function(params):\n",
    "    x1, x2, x3 = params['x1'], params['x2'], params['x3']\n",
    "    return -((x1 - 3)**2 + (x2 - 5)**2 - x3 + np.random.normal(0, 0.1))\n",
    "\n",
    "n_iter = 20\n",
    "all_params = []\n",
    "all_results = []\n",
    "\n",
    "best_params = None\n",
    "best_value = float('inf')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    sampled_params = {\n",
    "        'x1': random.uniform(0, 10),\n",
    "        'x2': random.uniform(0, 10),\n",
    "        'x3': random.choice([1, 2, 3])\n",
    "    }\n",
    "\n",
    "    value = objective_function(sampled_params)\n",
    "\n",
    "    all_params.append(sampled_params)\n",
    "    all_results.append(value)\n",
    "\n",
    "    if value < best_value:\n",
    "        best_value = value\n",
    "        best_params = sampled_params\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(f\"Iteration {i+1}: Params = {all_params[i]}, Objective Value = {all_results[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPaZjVKkYH0D"
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2XPQk7f79nl"
   },
   "outputs": [],
   "source": [
    "# digits - decision tree\n",
    "keys, values = zip(*param_distributions_dt.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "dt_results = []\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_default = dt_clf.predict(X_test)\n",
    "y_pred_default_proba = dt_clf.predict_proba(X_test)\n",
    "default_accuracy = accuracy_score(y_test, y_pred_default)\n",
    "default_roc_auc = roc_auc_score(y_test_bin, y_pred_default_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "best_accuracy = 0\n",
    "best_roc_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "for params in param_combinations:\n",
    "    dt_clf = DecisionTreeClassifier(\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        criterion=params['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "    y_pred_proba = dt_clf.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and roc_auc > best_roc_auc):\n",
    "        best_accuracy = accuracy\n",
    "        best_roc_auc = roc_auc\n",
    "        best_params = params\n",
    "\n",
    "dt_results.append({\n",
    "    'dataset': 'digits',\n",
    "    'best_params': best_params,\n",
    "    'accuracy': best_accuracy,\n",
    "    'roc_auc': best_roc_auc,\n",
    "    'default_accuracy': default_accuracy,\n",
    "    'default_roc_auc': default_roc_auc,\n",
    "    'n_iter': len(param_combinations)\n",
    "})\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier Manual Grid Search Results:\")\n",
    "for result in dt_results:\n",
    "    print(f\"Dataset: {result['dataset']}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
    "    print(f\"Tuned Accuracy: {result['accuracy']}\")\n",
    "    print(f\"Tuned ROC AUC: {result['roc_auc']}\")\n",
    "    print(f\"Default Accuracy: {result['default_accuracy']}\")\n",
    "    print(f\"Default ROC AUC: {result['default_roc_auc']}\")\n",
    "    print(f\"Number of Iterations: {result['n_iter']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raFVZ9PN8OGS"
   },
   "source": [
    "DecisionTreeClassifier Manual Grid Search Results:\\\n",
    "Dataset: digits\\\n",
    "Best Hyperparameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy'}\\\n",
    "Tuned Accuracy: 0.8944444444444445\\\n",
    "Tuned ROC AUC: 0.9447431743279776\\\n",
    "Default Accuracy: 0.8416666666666667\\\n",
    "Default ROC AUC: 0.9117326702800151\\\n",
    "Number of Iterations: 4940"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrZ_Dx24xCfj"
   },
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DxoKhqexRzx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "class bayesian_optimization():\n",
    "    def __init__(self, objective, space, iterations=30, explore='ei', min_start_size=10):\n",
    "        self.objective = objective\n",
    "        self.space = space\n",
    "        self.feature_name = list(space.keys())\n",
    "        self.iterations = iterations\n",
    "        self.model = GaussianProcessRegressor(kernel=RBF(), alpha=1e-6, normalize_y=True)\n",
    "        self.explore = self.exploration_strategy(explore)\n",
    "        self.min_start_size = min_start_size\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.preprocess()\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.feature_num = len(self.space)\n",
    "        self.feature_type = {}\n",
    "        for feature, value in self.space.items():\n",
    "            if isinstance(value, list):\n",
    "                self.feature_type[feature] = 'categorical'\n",
    "            else:\n",
    "                assert(isinstance(value, tuple))\n",
    "                self.feature_type[feature] = 'continuous'\n",
    "\n",
    "    def feature_dict_to_array(self, feature_dicts):\n",
    "        # print(feature_dicts)\n",
    "        feature_array = np.zeros((len(feature_dicts), self.feature_num))\n",
    "        for i, feature in enumerate(self.feature_name):\n",
    "            for j, feature_dict in enumerate(feature_dicts):\n",
    "                feature_array[j, i] = feature_dict[feature]\n",
    "        return feature_array\n",
    "\n",
    "    def feature_array_to_dict(self, feature_array):\n",
    "        feature_dict = []\n",
    "        for i in range(feature_array.shape[0]):\n",
    "            feature_dict.append(dict(zip(self.feature_name, feature_array[i])))\n",
    "        return feature_dict\n",
    "\n",
    "\n",
    "    def random_sample(self, sample_size=5):\n",
    "        from tqdm import tqdm\n",
    "        candidates = {}\n",
    "        # for feature, value in tqdm(self.space.items()):\n",
    "        for feature, value in self.space.items():\n",
    "            if self.feature_type[feature] == 'categorical':\n",
    "                candidates[feature] = np.random.choice(value, sample_size)\n",
    "            else:\n",
    "                assert(self.feature_type[feature] == 'continuous')\n",
    "                if value[1] > 1:\n",
    "                    candidates[feature] = np.random.randint(value[0], value[1], sample_size)\n",
    "                else:\n",
    "                    candidates[feature] = np.random.uniform(value[0], value[1], sample_size)\n",
    "        ret = []\n",
    "        for i in range(sample_size):\n",
    "            ret.append({key: candidates[key][i] for key in candidates})\n",
    "        return ret\n",
    "\n",
    "    def exploration_strategy(self, explore='ei'):\n",
    "        if explore == 'ei':\n",
    "            def ei(x, gp, y_min):\n",
    "                x = np.array(x)\n",
    "                mu, sigma = gp.predict(x, return_std=True)\n",
    "                sigma += 1e-9\n",
    "                improvement = y_min - mu\n",
    "                z = np.array(improvement) / np.array(sigma)\n",
    "                return improvement * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "            return ei\n",
    "        elif explore == 'greedy':\n",
    "            def greedy(x, gp, _):\n",
    "                mu, _ = gp.predict(x, return_std=True)\n",
    "                return -mu\n",
    "            return greedy\n",
    "        elif explore == 'ucb':\n",
    "            def ucb(x, gp, _):\n",
    "                mu, sigma = gp.predict(x, return_std=True)\n",
    "                return mu + 1.96 * sigma\n",
    "            return ucb\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported exploration strategy. Use 'ei', 'greedy', or 'ucb'.\")\n",
    "\n",
    "    def get_next_point(self, sample_size=5, return_size=1):\n",
    "        candidates = self.random_sample(sample_size)\n",
    "        candidates = self.feature_dict_to_array(candidates)\n",
    "        acq_values = self.explore(candidates, self.model, min(self.Y))\n",
    "        best_indices = np.argsort(acq_values)[-return_size:]\n",
    "        return candidates[best_indices]\n",
    "\n",
    "    def update_model(self):\n",
    "        self.model.fit(self.feature_dict_to_array(self.X), np.array(self.Y))\n",
    "\n",
    "    def run(self):\n",
    "        from tqdm import tqdm\n",
    "        for i in tqdm(range(self.iterations)):\n",
    "            # print(f\"Iteration {i+1}/{self.iterations}\")\n",
    "            if len(self.X) < self.min_start_size:\n",
    "                x_next = self.random_sample(self.min_start_size)\n",
    "            else:\n",
    "                x_next = self.get_next_point()\n",
    "                x_next = self.feature_array_to_dict(x_next)\n",
    "\n",
    "            y_next = []\n",
    "            for x in x_next:\n",
    "                y_next.append(self.objective(x))\n",
    "            # print(y_next)\n",
    "            self.X.extend(x_next)\n",
    "            self.Y.extend(y_next)\n",
    "            self.update_model()\n",
    "            print(f\"iter{i+1}, Best value so far: {min(self.Y)}\")\n",
    "\n",
    "        best_idx = np.argmin(self.Y)\n",
    "        return {\"best_x\": self.X[best_idx], \"best_y\": self.Y[best_idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdPx369kfesC",
    "outputId": "d519c5ce-3ea1-41b7-8c21-b80d88d5c918"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_covtype\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import itertools\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_distributions_svm = {\n",
    "    'C': (0.0001, 1000),\n",
    "    'gamma': (0.000001, 10),\n",
    "    'kernel': [0, 1, 2],\n",
    "    'class_weight': [0, 1],\n",
    "    'shrinking': [0, 1],\n",
    "    'tol': (0.00001, 0.01),\n",
    "    'probability': [0, 1]\n",
    "}\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kernel_array = ['poly', 'rbf', 'sigmoid']\n",
    "class_weight_array = [None, 'balanced']\n",
    "shrinking_array = [True, False]\n",
    "probability_array = [True, False]\n",
    "\n",
    "\n",
    "def objective_svm(params):\n",
    "    params2 = params.copy()\n",
    "    params2['kernel'] = kernel_array[int(params['kernel'])]\n",
    "    params2['C'] = float(params['C'])\n",
    "    params2['class_weight'] = class_weight_array[int(params['class_weight'])]\n",
    "    params2['shrinking'] = shrinking_array[int(params['shrinking'])]\n",
    "    params2['probability'] = probability_array[int(params['probability'])]\n",
    "\n",
    "    model = SVC(**params2)\n",
    "    # model.fit(train_features, train_labels)\n",
    "    # y_pred = model.predict(test_features)\n",
    "    # accuracy = accuracy_score(test_labels, y_pred)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return -accuracy\n",
    "\n",
    "bo_svm = bayesian_optimization(\n",
    "    objective=objective_svm,\n",
    "    space=param_distributions_svm,\n",
    "    iterations=25,\n",
    "    explore='ei',\n",
    "    min_start_size=1,\n",
    ")\n",
    "\n",
    "result_svm = bo_svm.run()\n",
    "print(\"SVM最佳超参数配置:\", result_svm[\"best_x\"])\n",
    "print(\"SVM最佳目标值:\", result_svm[\"best_y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODU633A8xUED",
    "outputId": "ea10c27e-626b-4a78-aac8-712248a49e80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best config: [2.97526837 5.03082013]\n",
      "best result: -9.02749861465481e-05\n"
     ]
    }
   ],
   "source": [
    "param_distributions_lgb = {\n",
    "    # 'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'boosting_type': [0, 1, 2],\n",
    "    'num_leaves': (20, 150),\n",
    "    'learning_rate': (0.005, 0.5),\n",
    "    'subsample_for_bin': (20000, 300000),\n",
    "    'min_child_samples': (20, 500),\n",
    "    'reg_alpha': (0, 1),\n",
    "    'reg_lambda': (0, 1),\n",
    "    'colsample_bytree': (0.6, 1),\n",
    "    'subsample': (0.5, 1),\n",
    "    # 'is_unbalance': [True, False]\n",
    "    'is_unbalance': [0, 1]\n",
    "}\n",
    "type_array = ['gbdt', 'goss', 'dart']\n",
    "unbalance_array = [True, False]\n",
    "def objective_lgb(params):\n",
    "    params2 = params.copy()\n",
    "    params2['boosting_type'] = type_array[int(params['boosting_type'])]\n",
    "    params2['is_unbalance'] = unbalance_array[int(params['is_unbalance'])]\n",
    "    params2['num_leaves'] = int(params['num_leaves'])\n",
    "    params2['subsample_for_bin'] = int(params['subsample_for_bin'])\n",
    "    params2['min_child_samples'] = int(params['min_child_samples'])\n",
    "    model = lgb.LGBMClassifier(**params2, random_state=42, force_col_wise=True, verbose=-1)\n",
    "    model.fit(train_features, train_labels)\n",
    "    y_pred = model.predict(test_features)\n",
    "    return -accuracy_score(test_labels, y_pred)\n",
    "\n",
    "bo = bayesian_optimization(\n",
    "    objective=objective_lgb,\n",
    "    space=param_distributions_lgb,\n",
    "    iterations=25,\n",
    "    explore='ei',\n",
    "    min_start_size=5,\n",
    ")\n",
    "\n",
    "result = bo.run()\n",
    "\n",
    "# 打印结果\n",
    "print(\"最佳超参数配置:\", result[\"best_x\"])\n",
    "print(\"最佳目标值:\", result[\"best_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPrrE5lR0rqC"
   },
   "outputs": [],
   "source": [
    "# digits - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1usLZN7G0r7h"
   },
   "outputs": [],
   "source": [
    "# kaggle dataset - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4NUvO090sPz"
   },
   "outputs": [],
   "source": [
    "# kaggle dataset - gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqMW8TmsJMmP"
   },
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssukyTC29N27"
   },
   "outputs": [],
   "source": [
    "class q_learning():\n",
    "    def __init__(self, alpha, gamma, epsilon, proportional_factor, max_iterations,\n",
    "                 space, model, X_train, y_train, X_test, y_test):\n",
    "        self.q_table = {}\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.proportional_factor = proportional_factor\n",
    "        self.max_iterations = max_iterations\n",
    "        self.space = space\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.actions = {key: [\"increase\", \"stay\", \"decrease\"] for key in self.space.keys()}\n",
    "\n",
    "    def state_selection(self):\n",
    "        state = {}\n",
    "        for key, values in self.space.items():\n",
    "            if type(values) == list:\n",
    "                state[key] = random.choice(values)\n",
    "            else:\n",
    "                state[key] = random.uniform(values[0], values[1])\n",
    "        return state\n",
    "\n",
    "    def exploration_strategy(self, state):\n",
    "        action_set = {}\n",
    "        for key in self.space.keys():\n",
    "            if random.uniform(0, 1) < self.epsilon:\n",
    "                action_set[key] = random.choice(self.actions[key])\n",
    "            else:\n",
    "                q_values = self.q_table.get(tuple(state.items()), {}).get(key, {})\n",
    "                action_set[key] = max(q_values, key=q_values.get, default=\"stay\")\n",
    "            self.epsilon *= 0.999\n",
    "        return action_set\n",
    "\n",
    "    def apply_action(self, state, action_set):\n",
    "        new_state = state.copy()\n",
    "\n",
    "        for key, action in action_set.items():\n",
    "            if type(self.space[key]) == list:\n",
    "                value_list = self.space[key]\n",
    "                current_index = value_list.index(new_state[key])\n",
    "\n",
    "                if action == \"increase\":\n",
    "                    new_index = min(current_index + 1, len(value_list) - 1)\n",
    "                elif action == \"decrease\":\n",
    "                    new_index = max(current_index - 1, 0)\n",
    "                else:\n",
    "                    new_index = current_index\n",
    "\n",
    "                new_state[key] = value_list[new_index]\n",
    "\n",
    "            else:\n",
    "                min_val, max_val = self.space[key]\n",
    "                current_value = new_state[key]\n",
    "                self.proportional_factor *= 0.99\n",
    "\n",
    "                if action == \"increase\":\n",
    "                    new_state[key] = min((1 + self.proportional_factor) * current_value, max_val)\n",
    "                elif action == \"decrease\":\n",
    "                    new_state[key] = max((1 - self.proportional_factor) * current_value, min_val)\n",
    "                else:\n",
    "                    new_state[key] = current_value\n",
    "        return new_state\n",
    "\n",
    "    def get_reward(self, state):\n",
    "        params = {k: v for k, v in state.items()}\n",
    "\n",
    "        if self.model == \"dt\":\n",
    "            model = DecisionTreeClassifier(**params, random_state=42)\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            return accuracy_score(self.y_test, y_pred)\n",
    "        else:\n",
    "            return -((state['x1'] - 3)**2 + (state['x2'] - 5)**2  - (state['x3']) + np.random.normal(0, 0.1))\n",
    "\n",
    "    def update_q_table(self, state, action_set, reward, new_state):\n",
    "        state_key = tuple(state.items())\n",
    "        new_state_key = tuple(new_state.items())\n",
    "\n",
    "        if state_key not in self.q_table:\n",
    "            self.q_table[state_key] = {}\n",
    "        for key, action in action_set.items():\n",
    "            if key not in self.q_table[state_key]:\n",
    "                self.q_table[state_key][key] = {}\n",
    "            old_q_value = self.q_table[state_key][key].get(action, 0)\n",
    "            future_q_value = max(\n",
    "                self.q_table.get(new_state_key, {}).get(key, {}).values(), default=0\n",
    "            )\n",
    "            new_q_value = old_q_value + self.alpha * (reward + self.gamma * future_q_value - old_q_value)\n",
    "            self.q_table[state_key][key][action] = new_q_value\n",
    "\n",
    "    def run(self):\n",
    "        for iteration in range(self.max_iterations):\n",
    "            state = {key: random.choice(values) for key, values in self.space.items()}\n",
    "\n",
    "            for _ in range(100):\n",
    "                action_set = self.exploration_strategy(state)\n",
    "                new_state = self.apply_action(state, action_set)\n",
    "                reward = self.get_reward(new_state)\n",
    "                self.update_q_table(state, action_set, reward, new_state)\n",
    "                state = new_state\n",
    "        print(len(self.q_table))\n",
    "\n",
    "    def get_best_hyperparameters(self):\n",
    "        self.run()\n",
    "        best_state = max(\n",
    "            (s for s in self.q_table if self.q_table[s]),\n",
    "            key=lambda s: sum(max(self.q_table[s][k].values(), default=0) for k in self.q_table[s]),\n",
    "            default=None\n",
    "        )\n",
    "        return dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0d6zObS1qUw",
    "outputId": "b5b1946b-31d4-4d02-f3ed-38a65317b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "307\n",
      "293\n",
      "193\n",
      "173\n",
      "310\n",
      "242\n",
      "297\n",
      "186\n",
      "208\n",
      "[{'x1': 0.0, 'x2': 9.660738000321029, 'x3': 2}, {'x1': 0.0, 'x2': 6.2129964532848785, 'x3': 3}, {'x1': 4.529635585505561, 'x2': 6.76942991422106, 'x3': 3}, {'x1': 0.0, 'x2': 9.999999999682311, 'x3': 2}, {'x1': 0.0, 'x2': 8.31837142031841, 'x3': 2}, {'x1': 0.0, 'x2': 9.844845852239574, 'x3': 2}, {'x1': 0.0, 'x2': 7.0780149854224605, 'x3': 3}, {'x1': 7.998077289440447, 'x2': 5.03982081954357, 'x3': 2}, {'x1': 0.0, 'x2': 9.999999998209683, 'x3': 2}, {'x1': 0.0, 'x2': 9.343649606355054, 'x3': 3}]\n",
      "[-28.655266166704706, -7.360572355462452, -2.496523487789181, -32.05893780729479, -18.104293723430466, -30.451764081070646, -10.274507617817937, -22.90105920367276, -31.94459964484592, -24.75964627251292]\n",
      "-2.496523487789181\n"
     ]
    }
   ],
   "source": [
    "# obj function\n",
    "params = []\n",
    "results = []\n",
    "for _ in range(10):\n",
    "    ql = q_learning(\n",
    "        alpha = 0.1,\n",
    "        gamma = 0.9,\n",
    "        epsilon = 0.9,\n",
    "        proportional_factor = 0.1,\n",
    "        max_iterations = 20,\n",
    "        space = param_distributions_obj,\n",
    "        model = \"obj\",\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test\n",
    "    )\n",
    "    result = ql.get_best_hyperparameters()\n",
    "    loss = -((result['x1'] - 3)**2 + (result['x2'] - 5)**2  - (result['x3']) + np.random.normal(0, 0.1))\n",
    "\n",
    "    params.append(result)\n",
    "    results.append(loss)\n",
    "\n",
    "print(params)\n",
    "print(results)\n",
    "print(max(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yCVLaUv17dA",
    "outputId": "fb061ed1-098d-4647-e936-72517891f897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.8724999999999999\n",
      "Minimum: 0.8361111111111111\n",
      "Maximum: 0.8888888888888888\n",
      "Standard Deviation: 0.013858299648073781\n"
     ]
    }
   ],
   "source": [
    "dt_result = [0.8722222222222222, 0.8694444444444445, 0.8694444444444445, 0.8722222222222222, 0.875, 0.8888888888888888, 0.8888888888888888, 0.875, 0.8361111111111111, 0.8777777777777778]\n",
    "\n",
    "mean = np.mean(dt_result)\n",
    "minimum = np.min(dt_result)\n",
    "maximum = np.max(dt_result)\n",
    "std_dev = np.std(dt_result)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Minimum:\", minimum)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Standard Deviation:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CzP7jyVJwPY",
    "outputId": "c9afd756-e7cd-4b0a-8080-27017b7d9c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -20.90071703606018\n",
      "Minimum: -32.05893780729479\n",
      "Maximum: -2.496523487789181\n",
      "Standard Deviation: 10.29323873933181\n"
     ]
    }
   ],
   "source": [
    "obj_result = [-28.655266166704706, -7.360572355462452, -2.496523487789181, -32.05893780729479, -18.104293723430466, -30.451764081070646, -10.274507617817937, -22.90105920367276, -31.94459964484592, -24.75964627251292]\n",
    "mean = np.mean(obj_result)\n",
    "minimum = np.min(obj_result)\n",
    "maximum = np.max(obj_result)\n",
    "std_dev = np.std(obj_result)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Minimum:\", minimum)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Standard Deviation:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a11myRemJ6WN",
    "outputId": "a28d141a-d8a9-4854-e252-86715ce3791a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4722222222222222\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'criterion': 'gini'\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier(**params, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nFP9hElCs8a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
